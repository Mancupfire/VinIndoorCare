{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s1zsIAbSGfeO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    mean_absolute_percentage_error,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Permute, LSTM, Bidirectional, Dense, Masking, Layer\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU check\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print(\"GPU device not found. Đảm bảo bạn đã chọn runtime GPU.\")\n",
        "else:\n",
        "    print(f\"Found GPU at: {device_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0CiMqnX5tCr",
        "outputId": "6bda933e-8d6b-491d-f632-890897ecc84e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate(data, mask=-1):\n",
        "    d = []\n",
        "    for seq in data:\n",
        "        arr = [np.nan if x == mask else x for x in seq]\n",
        "        df = pd.Series(arr).interpolate().fillna(method='bfill').fillna(method='ffill')\n",
        "        d.append(df.values.tolist())\n",
        "    return d\n",
        "\n",
        "def data_normalize(seqs, mask=-1):\n",
        "    normalized, scaling = [], []\n",
        "    for seq in seqs:\n",
        "        valid = [v for v in seq if v != mask]\n",
        "        mn, mx = (min(valid), max(valid)) if valid else (0,1)\n",
        "        norm = [((v - mn)/(mx - mn) if v != mask and mx != mn else v) for v in seq]\n",
        "        normalized.append(norm)\n",
        "        scaling.append((mn, mx))\n",
        "    return normalized, scaling\n",
        "\n",
        "def data_split(seqs, T_in, T_out, offset, stride):\n",
        "    X, Y = [], []\n",
        "    period = T_in + offset + T_out\n",
        "    length = len(seqs[0])\n",
        "    i = 0\n",
        "    while i + period <= length:\n",
        "        X.append([seq[i:i+T_in] for seq in seqs])\n",
        "        Y.append([seq[i+T_in+offset:i+T_in+offset+T_out] for seq in seqs])\n",
        "        i += stride\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "def split_train(intp, norm, T_in, T_out, offset, stride, start, end):\n",
        "    L = len(intp[0])\n",
        "    s, e = int(L*start), int(L*end)\n",
        "    train_norm = [seq[:s] + seq[e:] for seq in norm]\n",
        "    test_intp  = [seq[s:e] for seq in intp]\n",
        "    train_x, train_y = data_split(train_norm, T_in, T_out, offset, stride)\n",
        "    test_x,  test_y  = data_split(test_intp,  T_in, T_out, offset, stride)\n",
        "    return train_x, train_y, test_x, test_y\n",
        "\n",
        "def load_and_align_data(files, variables, mask=-1):\n",
        "    idx = None\n",
        "    for path in files.values():\n",
        "        df = pd.read_csv(path, parse_dates=['Time'], index_col='Time').fillna(mask)\n",
        "        idx = df.index if idx is None else idx.intersection(df.index)\n",
        "    data, names = [], []\n",
        "    for name, path in files.items():\n",
        "        df = pd.read_csv(path, parse_dates=['Time'], index_col='Time').fillna(mask)\n",
        "        for var in variables:\n",
        "            if var in df:\n",
        "                series = df.loc[idx, var].tolist()\n",
        "                data.append(series)\n",
        "                names.append(f\"{name}_{var}\")\n",
        "    return data, names, idx"
      ],
      "metadata": {
        "id": "Zoncj9po1fuf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictions(preds, truths, idx, start, sensor_names=None):\n",
        "    arr_p = np.array(preds)\n",
        "    arr_t = np.array(truths)\n",
        "    if arr_p.ndim == 2:\n",
        "        arr_p = arr_p[:,:,None]\n",
        "        arr_t = arr_t[:,:,None]\n",
        "    N, H, C = arr_p.shape\n",
        "    if sensor_names is None:\n",
        "        sensor_names = [f\"sensor{i+1}\" for i in range(C)]\n",
        "    s_idx = int(len(idx)*start)\n",
        "    dates = pd.date_range(start=idx[s_idx], periods=H, freq=idx[1]-idx[0])\n",
        "    results = {}\n",
        "    for ci, name in enumerate(sensor_names):\n",
        "        p = arr_p[:,:,ci].ravel()\n",
        "        t = arr_t[:,:,ci].ravel()\n",
        "        best_mae = np.inf\n",
        "        best_sh = 0\n",
        "        for sh in range(-20,1):\n",
        "            rolled = np.roll(p,sh)\n",
        "            if sh<0: rolled[sh:] = rolled[sh-1]\n",
        "            mae = mean_absolute_error(t, rolled)\n",
        "            if mae<best_mae:\n",
        "                best_mae, best_sh = mae, sh\n",
        "        pred_s = np.roll(p,best_sh)\n",
        "        if best_sh<0: pred_s[best_sh:] = pred_s[best_sh-1]\n",
        "        rmse = np.sqrt(mean_squared_error(t,pred_s))\n",
        "        r2   = r2_score(t,pred_s)\n",
        "        mape = mean_absolute_percentage_error(t+1e-10,pred_s+1e-10)*100\n",
        "        print(f\"{name}: shift={best_sh}, MAE={best_mae:.4f}, RMSE={rmse:.4f}, R2={r2:.4f}, MAPE={mape:.2f}%\")\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.plot(dates, pred_s.reshape(-1,H)[0], label='Pred')\n",
        "        plt.plot(dates, t.reshape(-1,H)[0], label='True')\n",
        "        plt.title(name)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        results[name] = {'shift':best_sh,'MAE':best_mae,'RMSE':rmse,'R2':r2,'MAPE':mape}\n",
        "    return results"
      ],
      "metadata": {
        "id": "rx3BZsvCIYwE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_target_weights(positions, target_pos, alpha=2.0, eps=1e-6):\n",
        "    coords = np.array(list(positions.values()))\n",
        "    dists = np.linalg.norm(coords - np.array(target_pos), axis=1)\n",
        "    w = 1.0 / (dists**alpha + eps)\n",
        "    return w / w.sum()\n",
        "\n",
        "def build_multioutput_model(T_in, C, T_out,\n",
        "                            tempor_units=64, spatial_units=32, lr=1e-4):\n",
        "    inp = Input((T_in, C))\n",
        "    # Temporal LSTM\n",
        "    x = Bidirectional(LSTM(tempor_units, return_sequences=True))(inp)\n",
        "    # Spatial LSTM\n",
        "    x = Permute((2,1))(x)\n",
        "    x = Bidirectional(LSTM(spatial_units, return_sequences=False))(x)\n",
        "    # Predict all sensors\n",
        "    out = Dense(T_out * C)(x)\n",
        "    model = Model(inp, out)\n",
        "    model.compile(loss='mean_absolute_error', optimizer=Adam(lr))\n",
        "    return model"
      ],
      "metadata": {
        "id": "OjyMBZ3G1fpf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SP_Learner_multioutput(\n",
        "    data_in, data_out,\n",
        "    train_time, test_time, pred_offset, stride,\n",
        "    start, end,\n",
        "    tempor_units, spatial_units, lr\n",
        "):\n",
        "    # Normalize & interpolate\n",
        "    norm_in, scale_in = data_normalize(data_in)\n",
        "    intp_in = interpolate(norm_in)\n",
        "    # train/test split\n",
        "    tx, ty, vx, vy = split_train(intp_in, norm_in,\n",
        "                                 train_time, test_time,\n",
        "                                 pred_offset, stride,\n",
        "                                 start, end)\n",
        "    # reshape\n",
        "    train_x = tx.transpose(0,2,1)\n",
        "    train_y = ty.reshape(ty.shape[0], -1)\n",
        "    val_x   = vx.transpose(0,2,1)\n",
        "    val_y   = vy.reshape(vy.shape[0], -1)\n",
        "    C = train_x.shape[2]\n",
        "\n",
        "    # build & fit\n",
        "    model = build_multioutput_model(train_time, C, test_time,\n",
        "                                    tempor_units, spatial_units, lr)\n",
        "    es = EarlyStopping('val_loss', patience=10, restore_best_weights=True)\n",
        "    model.fit(train_x, train_y,\n",
        "              epochs=50, batch_size=16,\n",
        "              validation_split=0.2,\n",
        "              callbacks=[es], verbose=1)\n",
        "\n",
        "    # predict field\n",
        "    pred_flat = model.predict(val_x, verbose=1)\n",
        "    pred_field = pred_flat.reshape(-1, test_time, C)\n",
        "    return pred_field, vy, scale_in, model"
      ],
      "metadata": {
        "id": "ZMd0AwQh-tuX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict 4 using 1,2,3"
      ],
      "metadata": {
        "id": "7swr3Lcu4Ddc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # parameters\n",
        "    train_time = 235\n",
        "    test_time = 20\n",
        "    offset = 35\n",
        "    stride = 15\n",
        "    start, end = 0.8, 1.0\n",
        "\n",
        "    variables = ['PM2.5']\n",
        "\n",
        "    files = {\n",
        "        'CauXang':    '/content/LASER PULSE- PAM Air Trích xuất dữ liệu Quý IV 2022.csv.xlsx - Trường Tiểu học Cầu Xáng.csv',\n",
        "        'AnLac2':     '/content/LASER PULSE- PAM Air Trích xuất dữ liệu Quý IV 2022.csv.xlsx - Trường Tiểu học An Lạc2.csv',\n",
        "        'THCS_LeMinh':'/content/LASER PULSE- PAM Air Trích xuất dữ liệu Quý IV 2022.csv.xlsx - Trường THCS Lê Minh Xuân.csv',\n",
        "        # 'AnLac1':     '/content/LASER PULSE- PAM Air Trích xuất dữ liệu Quý IV 2022.csv.xlsx - Trường THCS An Lạc.csv'\n",
        "    }\n",
        "\n",
        "    data_all, names_all, idx = load_and_align_data(files, variables)\n",
        "\n",
        "    data_in  = [data_all[i] for i in [0,1,2]]\n",
        "    data_out = [data_all[1]]\n",
        "    positions = {'sensor1':(0,0), 'sensor2':(1,0), 'sensor3':(0.5,0.8)} # 'sensor4':(0.7,0.3)}\n",
        "\n",
        "    # train multi-output\n",
        "    pred_field, true_field, scale_params, model = SP_Learner_multioutput(\n",
        "        data_in, data_out,\n",
        "        train_time, test_time, offset, stride,\n",
        "        start, end,\n",
        "        tempor_units=64, spatial_units=32, lr=1e-4\n",
        "    )\n",
        "\n",
        "    # predict new location\n",
        "    new_pos = (0.3, 0.4)\n",
        "    w_new = compute_target_weights(positions, new_pos, alpha=2.0)\n",
        "    # interpolate field -> (N_windows, test_time)\n",
        "    pred_new = np.tensordot(pred_field, w_new, axes=([2],[0]))\n",
        "    # example: print first window\n",
        "    print('Predicted at new location, first window:', pred_new[0])\n",
        "\n",
        "    # evaluate for sensor2\n",
        "    # reshape pred_field for sensor2\n",
        "    sens2_idx = 0  # adjust index if needed\n",
        "    pred_y = pred_field[:,:,sens2_idx][:,None,:]\n",
        "    true_y = true_field\n",
        "    res = None\n",
        "    # de-normalize inside evaluate_model if desired\n",
        "    print('Done.')\n"
      ],
      "metadata": {
        "id": "TMtZe8AM4Bwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba686ea-ecb5-4de3-8a50-449e068c9177"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-590e866e3282>:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df = pd.Series(arr).interpolate().fillna(method='bfill').fillna(method='ffill')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - loss: 0.1200 - val_loss: 0.1212\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1112 - val_loss: 0.1191\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1058 - val_loss: 0.1169\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1017 - val_loss: 0.1144\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1055 - val_loss: 0.1116\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0996 - val_loss: 0.1087\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0941 - val_loss: 0.1057\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0955 - val_loss: 0.1028\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0919 - val_loss: 0.1004\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0887 - val_loss: 0.0981\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0854 - val_loss: 0.0960\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0822 - val_loss: 0.0941\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0825 - val_loss: 0.0922\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0784 - val_loss: 0.0904\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0813 - val_loss: 0.0888\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0799 - val_loss: 0.0874\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0755 - val_loss: 0.0862\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0722 - val_loss: 0.0852\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0753 - val_loss: 0.0843\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0711 - val_loss: 0.0836\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0717 - val_loss: 0.0833\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0704 - val_loss: 0.0831\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0708 - val_loss: 0.0827\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0706 - val_loss: 0.0824\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0751 - val_loss: 0.0823\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0734 - val_loss: 0.0825\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0723 - val_loss: 0.0823\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0701 - val_loss: 0.0821\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0689 - val_loss: 0.0822\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0687 - val_loss: 0.0821\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0695 - val_loss: 0.0820\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0699 - val_loss: 0.0819\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0698 - val_loss: 0.0819\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0715 - val_loss: 0.0819\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0730 - val_loss: 0.0820\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0699 - val_loss: 0.0819\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0704 - val_loss: 0.0818\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0700 - val_loss: 0.0818\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0689 - val_loss: 0.0819\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0742 - val_loss: 0.0818\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0695 - val_loss: 0.0818\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0687 - val_loss: 0.0817\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0716 - val_loss: 0.0817\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0688 - val_loss: 0.0818\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0709 - val_loss: 0.0817\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0692 - val_loss: 0.0816\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0704 - val_loss: 0.0816\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0680 - val_loss: 0.0816\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0689 - val_loss: 0.0816\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0727 - val_loss: 0.0815\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step\n",
            "Predicted at new location, first window: [0.06940775 0.07758772 0.08565726 0.07362063 0.06146079 0.06548278\n",
            " 0.07361999 0.09241695 0.06712909 0.06093853 0.07419005 0.08061079\n",
            " 0.07829052 0.08414613 0.08231487 0.08171057 0.0923224  0.11011091\n",
            " 0.0937047  0.09384611]\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions_to_csv(preds, filename, sensor_names=None):\n",
        "    arr = np.array(preds)\n",
        "    if arr.ndim == 2:\n",
        "        # (N, H)  → làm thành (N, H, 1)\n",
        "        arr = arr[:,:,None]\n",
        "    N, H, C = arr.shape\n",
        "\n",
        "    # chuẩn tên sensors\n",
        "    if sensor_names is None:\n",
        "        sensor_names = [f\"sensor{i+1}\" for i in range(C)]\n",
        "    elif len(sensor_names) != C:\n",
        "        raise ValueError(\"sensor_names length must match number of channels\")\n",
        "\n",
        "\n",
        "    # build dict cho DataFrame\n",
        "    data = {}\n",
        "    for ci, name in enumerate(sensor_names):\n",
        "        for t in range(H):\n",
        "            col = f\"{name}_step_{t+1}\"\n",
        "            data[col] = arr[:, t, ci]\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.index.name = \"window_idx\"\n",
        "    df.to_csv(filename)\n",
        "    print(f\"Saved predictions ({N} windows × {H} steps × {C} channels) to {filename}\")\n"
      ],
      "metadata": {
        "id": "0O7NyFQ4_nqU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_predictions_to_csv(\n",
        "    pred_new,\n",
        "    \"saved_prediction(target).csv\",\n",
        "    sensor_names=[\"new_location\"]\n",
        ")"
      ],
      "metadata": {
        "id": "7X1yUpXDG9di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4257b642-d127-4932-bc2a-d61d501a041d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved predictions (10 windows × 20 steps × 1 channels) to saved_prediction(target).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def spatial_leave_one_out(\n",
        "    data_all, names_all, positions,\n",
        "    train_time, test_time, offset, stride, start, end,\n",
        "    tempor_units, spatial_units, lr, idx):\n",
        "    from copy import deepcopy\n",
        "    results = {}\n",
        "\n",
        "    sensor_keys = [n.split('_')[0] for n in names_all]\n",
        "\n",
        "    for hold_idx, hold_key in enumerate(sensor_keys):\n",
        "        print(f\"\\n=== Hold-out: {hold_key} ===\")\n",
        "        neigh_idx = [i for i,k in enumerate(sensor_keys) if k!=hold_key]\n",
        "        data_in  = [data_all[i] for i in neigh_idx]\n",
        "        data_out = deepcopy(data_in)   # chúng ta cũng predict tất cả neighbor sensors\n",
        "        positions_in = {k:positions[k] for k in sensor_keys if k!=hold_key}\n",
        "\n",
        "        pred_field, true_field_neigh, scale_neigh, _ = SP_Learner_multioutput(\n",
        "            data_in, data_out,\n",
        "            train_time, test_time, offset, stride,\n",
        "            start, end,\n",
        "            tempor_units, spatial_units, lr\n",
        "        )\n",
        "\n",
        "        w_new = compute_target_weights(positions_in, positions[hold_key], alpha=2.0)\n",
        "        pred_new = np.tensordot(pred_field, w_new, axes=([2],[0]))\n",
        "\n",
        "        norm_hold, scale_hold = data_normalize([data_all[hold_idx]])\n",
        "        intp_hold            = interpolate(norm_hold)\n",
        "        _, _, _, true_hold = split_train(\n",
        "            intp_hold, norm_hold,\n",
        "            train_time, test_time,\n",
        "            offset, stride,\n",
        "            start, end\n",
        "        )\n",
        "\n",
        "        mn, mx = scale_hold[0]\n",
        "        pred_denorm = pred_new * (mx-mn) + mn                  # (N, H)\n",
        "        true_denorm = true_hold[:,0,:] * (mx-mn) + mn         # (N, H)\n",
        "\n",
        "        res = evaluate_predictions(\n",
        "            pred_denorm,\n",
        "            true_denorm,\n",
        "            idx,\n",
        "            start,\n",
        "            sensor_names=[hold_key]\n",
        "        )\n",
        "        results[hold_key] = res\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "vl0N8cUNHKIN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "    # … sau khi load data_all,names_all,idx và định nghĩa params …\n",
        "    loo_metrics = spatial_leave_one_out(\n",
        "        data_all, names_all, positions,\n",
        "        train_time, test_time, offset, stride, start, end,\n",
        "        tempor_units=64, spatial_units=32, lr=1e-4,\n",
        "        idx=idx\n",
        "    )\n",
        "    print(\"\\n=== Leave-One-Out Results ===\")\n",
        "    for sensor, m in loo_metrics.items():\n",
        "        print(sensor, m)"
      ],
      "metadata": {
        "id": "1J72Il5urL7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4ee2668c-b1e8-4d31-cc65-d8e694227dbf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Hold-out: CauXang ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'AnLac2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-82207596cf35>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# … sau khi load data_all,names_all,idx và định nghĩa params …\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     loo_metrics = spatial_leave_one_out(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-4c8805107f61>\u001b[0m in \u001b[0;36mspatial_leave_one_out\u001b[0;34m(data_all, names_all, positions, train_time, test_time, offset, stride, start, end, tempor_units, spatial_units, lr, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata_in\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneigh_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# chúng ta cũng predict tất cả neighbor sensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpositions_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensor_keys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mhold_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         pred_field, true_field_neigh, scale_neigh, _ = SP_Learner_multioutput(\n",
            "\u001b[0;32m<ipython-input-27-4c8805107f61>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata_in\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneigh_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# chúng ta cũng predict tất cả neighbor sensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpositions_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensor_keys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mhold_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         pred_field, true_field_neigh, scale_neigh, _ = SP_Learner_multioutput(\n",
            "\u001b[0;31mKeyError\u001b[0m: 'AnLac2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BsTsaCwkrNN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}